{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ka96-ajYzxVU"
   },
   "source": [
    "# Train Your Own Model and Convert It to TFLite\n",
    "\n",
    "This notebook uses the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
    "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "Fashion MNIST is intended as a drop-in replacement for the classic [MNIST](http://yann.lecun.com/exdb/mnist/) dataset—often used as the \"Hello, World\" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc.) in a format identical to that of the articles of clothing we'll use here.\n",
    "\n",
    "This uses Fashion MNIST for variety, and because it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code.\n",
    "\n",
    "We will use 60,000 images to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from TensorFlow. Import and load the Fashion MNIST data directly from TensorFlow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjOAfhgd__Sp"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pfyZKowNAQ4j",
    "outputId": "8a94ac17-d4e7-474f-e984-a5ed389f5352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Using TensorFlow Version: 2.9.1\n",
      "• GPU Device Found.\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# TensorFlow Datsets\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "\n",
    "# Helper Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "\n",
    "from os import getcwd\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "print('\\u2022 Using TensorFlow Version:', tf.__version__)\n",
    "print('\\u2022 GPU Device Found.' if tf.config.list_physical_devices('GPU') else '\\u2022 GPU Device Not Found. Running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tadPBTEiAprt"
   },
   "source": [
    "# Download Fashion MNIST Dataset\n",
    "\n",
    "We will use TensorFlow Datasets to load the Fashion MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "XcNwi6nFKneZ",
    "outputId": "8e0d8173-6dbd-4ef5-a70b-efc8e9d33802"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah contoh dalam train: 60000\n",
      "Jumlah kelas: 10\n"
     ]
    }
   ],
   "source": [
    "filePath = f\"{getcwd()}/../tmp2/\"\n",
    "\n",
    "(train_examples, validation_examples, test_examples), info = tfds.load('fashion_mnist', \n",
    "                                                                        data_dir=filePath,\n",
    "                                                                        with_info=True, \n",
    "                                                                        as_supervised=True, \n",
    "                                                                        split=['train[:80%]',\n",
    "                                                                               'train[80%:90%]',\n",
    "                                                                               'train[90%:]'])\n",
    "\n",
    "num_examples = info.splits['train'].num_examples\n",
    "num_classes = info.features['label'].num_classes\n",
    "\n",
    "print(\"Jumlah contoh dalam train:\", num_examples)\n",
    "print(\"Jumlah kelas:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class names are not included with the dataset, so we will specify them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-eAv71FRm4JE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: T-shirt_top, Label: 0\n",
      "Class: Trouser, Label: 1\n",
      "Class: Pullover, Label: 2\n",
      "Class: Dress, Label: 3\n",
      "Class: Coat, Label: 4\n",
      "Class: Sandal, Label: 5\n",
      "Class: Shirt, Label: 6\n",
      "Class: Sneaker, Label: 7\n",
      "Class: Bag, Label: 8\n",
      "Class: Ankle boot, Label: 9\n",
      "Jumlah kelas: 10\n",
      "Nama kelas: ['T-shirt_top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
      "Dataset berhasil dimuat dan informasi telah ditulis ke labels.txt\n"
     ]
    }
   ],
   "source": [
    "# Daftar nama kelas\n",
    "class_names = ['T-shirt_top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Menghasilkan pelabelan kelas otomatis\n",
    "class_labels = {class_name: index for index, class_name in enumerate(class_names)}\n",
    "\n",
    "# Menampilkan hasil pelabelan\n",
    "for class_name, label in class_labels.items():\n",
    "    print(f'Class: {class_name}, Label: {label}')\n",
    "    \n",
    "# Membuat file labels.txt dengan nama kelas\n",
    "with open('labels.txt', 'w') as f:\n",
    "    f.write('\\n'.join(class_names))\n",
    "    \n",
    "IMG_SIZE = 28\n",
    "\n",
    "print(\"Nama kelas:\", class_names)\n",
    "print(\"Dataset berhasil dimuat dan informasi telah ditulis ke labels.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAkuq0V0Aw2X"
   },
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example(image, label):\n",
    "    # Cast image to float32\n",
    "    image = tf.cast(image, tf.float32)\n",
    "        \n",
    "    # Normalize the image in the range [0, 1]\n",
    "    image = image / 255.0\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAlBlXOUMwqe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contoh batch training:\n",
      "Bentuk gambar: (256, 28, 28, 1)\n",
      "Bentuk label: (256,)\n",
      "Contoh batch validasi:\n",
      "Bentuk gambar: (256, 28, 28, 1)\n",
      "Bentuk label: (256,)\n",
      "Contoh batch uji:\n",
      "Bentuk gambar: (1, 28, 28, 1)\n",
      "Bentuk label: (1,)\n"
     ]
    }
   ],
   "source": [
    "# Specify the batch size\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Buat batch data untuk training dan validasi\n",
    "train_batches = train_examples.cache().shuffle(num_examples//4).batch(BATCH_SIZE).map(format_example).prefetch(1)\n",
    "validation_batches = validation_examples.cache().batch(BATCH_SIZE).map(format_example)\n",
    "test_batches = test_examples.map(format_example).batch(1)\n",
    "\n",
    "# Output contoh untuk memeriksa batch training\n",
    "for images, labels in train_batches.take(1):  # Ambil satu batch pertama dari training\n",
    "    print(\"Contoh batch training:\")\n",
    "    print(\"Bentuk gambar:\", images.shape)\n",
    "    print(\"Bentuk label:\", labels.shape)\n",
    "\n",
    "# Output contoh untuk memeriksa batch validasi\n",
    "for images, labels in validation_batches.take(1):  # Ambil satu batch pertama dari validasi\n",
    "    print(\"Contoh batch validasi:\")\n",
    "    print(\"Bentuk gambar:\", images.shape)\n",
    "    print(\"Bentuk label:\", labels.shape)\n",
    "\n",
    "# Output contoh untuk memeriksa batch uji\n",
    "for images, labels in test_batches.take(1):  # Ambil satu batch pertama dari test\n",
    "    print(\"Contoh batch uji:\")\n",
    "    print(\"Bentuk gambar:\", images.shape)\n",
    "    print(\"Bentuk label:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-topQaOm_LM"
   },
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "188/188 [==============================] - 29s 56ms/step - loss: 0.6131 - accuracy: 0.7840 - val_loss: 0.3975 - val_accuracy: 0.8573\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.3792 - accuracy: 0.8660 - val_loss: 0.3451 - val_accuracy: 0.8787\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 3s 13ms/step - loss: 0.3295 - accuracy: 0.8834 - val_loss: 0.3106 - val_accuracy: 0.8873\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.3007 - accuracy: 0.8923 - val_loss: 0.2981 - val_accuracy: 0.8905\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 4s 20ms/step - loss: 0.2803 - accuracy: 0.8996 - val_loss: 0.2816 - val_accuracy: 0.8968\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 3s 14ms/step - loss: 0.2613 - accuracy: 0.9056 - val_loss: 0.2794 - val_accuracy: 0.8967\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 3s 18ms/step - loss: 0.2450 - accuracy: 0.9115 - val_loss: 0.2525 - val_accuracy: 0.9078\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 3s 17ms/step - loss: 0.2340 - accuracy: 0.9154 - val_loss: 0.2586 - val_accuracy: 0.9025\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 4s 23ms/step - loss: 0.2220 - accuracy: 0.9191 - val_loss: 0.2520 - val_accuracy: 0.9070\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.2101 - accuracy: 0.9238 - val_loss: 0.2466 - val_accuracy: 0.9092\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Set the input shape to (28, 28, 1), kernel size=3, filters=16 and use ReLU activation\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "      \n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "      \n",
    "    # Set the number of filters to 32, kernel size to 3 and use ReLU activation \n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "      \n",
    "    # Flatten the output layer to 1 dimension\n",
    "    tf.keras.layers.Flatten(),\n",
    "      \n",
    "    # Add a fully connected layer with 64 hidden units and ReLU activation\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "      \n",
    "    # Attach a final softmax classification head with 10 units (for 10 classes)\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Set the appropriate loss function and use accuracy as your metric\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(train_batches, epochs=10, validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TZT9-7w9n4YO"
   },
   "source": [
    "# Exporting to TFLite\n",
    "\n",
    "You will now save the model to TFLite. We should note, that you will probably see some warning messages when running the code below. These warnings have to do with software updates and should not cause any errors or prevent your code from running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: Use the tf.saved_model API to save your model in the SavedModel format. \n",
    "# UNQ_C4\n",
    "# GRADED CODE: save_model\n",
    "\n",
    "export_dir = 'saved_model/1'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "tf.saved_model.save(model, export_dir)\n",
    "\n",
    "# Convert the SavedModel to TFLite format\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted TFLite model to a file\n",
    "tflite_model_file = 'model.tflite'\n",
    "with open(tflite_model_file, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"Model successfully saved to {tflite_model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "EDGiYrBdE6fl"
   },
   "outputs": [],
   "source": [
    "# Select mode of optimization\n",
    "mode = \"Speed\" \n",
    "\n",
    "if mode == 'Storage':\n",
    "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_SIZE\n",
    "elif mode == 'Speed':\n",
    "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_LATENCY\n",
    "else:\n",
    "    optimization = tf.lite.Optimize.DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized TFLite model successfully saved to optimized_model.tflite\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: Use the TFLiteConverter SavedModel API to initialize the converter\n",
    "# UNQ_C5\n",
    "# GRADED CODE: save_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initialize the TFLiteConverter with the SavedModel directory\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('saved_model/1')\n",
    "\n",
    "# Set optimizations to reduce the model size and improve performance\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Invoke the converter to generate the TFLite model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted TFLite model to a file\n",
    "tflite_model_file = 'optimized_model.tflite'\n",
    "with open(tflite_model_file, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"Optimized TFLite model successfully saved to {tflite_model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "q5PWCDsTC3El",
    "outputId": "97349e68-0bff-41cd-ad48-90a6abb85f11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259648"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_file = pathlib.Path('./model.tflite')\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SR6wFcQ1Fglm"
   },
   "source": [
    "# Test the Model with TFLite Interpreter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKcToCBEC-Bu"
   },
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E8EpFpIBFkq8"
   },
   "outputs": [],
   "source": [
    "# Gather results for the randomly sampled test images\n",
    "predictions = []\n",
    "test_labels = []\n",
    "test_images = []\n",
    "\n",
    "for img, label in test_batches.take(50):\n",
    "    interpreter.set_tensor(input_index, img)\n",
    "    interpreter.invoke()\n",
    "    predictions.append(interpreter.get_tensor(output_index))\n",
    "    test_labels.append(label[0])\n",
    "    test_images.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "kSjTmi05Tyod"
   },
   "outputs": [],
   "source": [
    "# Utilities functions for plotting\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    img = np.squeeze(img)\n",
    "    \n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "    \n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    \n",
    "    if predicted_label == true_label.numpy():\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "        \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                         100*np.max(predictions_array),\n",
    "                                         class_names[true_label]),\n",
    "                                         color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(list(range(10)))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array[0], color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array[0])\n",
    "    \n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')\n",
    "    \n",
    "# Visualize the outputs\n",
    "\n",
    "# Select index of image to display. Minimum index value is 1 and max index value is 50. \n",
    "index = 49 \n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(index, predictions, test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(index, predictions, test_labels)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TF Lite Week 1 Exercise - Answer",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "coursera": {
   "course_slug": "device-based-models-tensorflow",
   "graded_item_id": "sCFzO",
   "launcher_item_id": "fJyaf"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
